{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be attempting to use transfer learning to predict our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications import VGG16\n",
    "\n",
    "from pathlib import Path\n",
    "import imghdr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the data\n",
    "data_dir = \"./BBTrD/000000001111\"\n",
    "image_extensions = [\".png\", \".jpg\", \".jpeg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_labels():\n",
    "    txt_file_path = \"labels.txt\"\n",
    "    labels = []\n",
    "    with open(txt_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            labels.append(line.strip())\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000001111',\n",
       " '000000011110',\n",
       " '000000101101',\n",
       " '000000111100',\n",
       " '000001001011',\n",
       " '000001011010',\n",
       " '000001101001',\n",
       " '000001111000',\n",
       " '000010000111',\n",
       " '000010010110',\n",
       " '000010100101',\n",
       " '000010110100',\n",
       " '000011000011',\n",
       " '000011010010',\n",
       " '000011100001',\n",
       " '000011110000',\n",
       " '000100001110',\n",
       " '000100101100',\n",
       " '000101001010',\n",
       " '000101101000',\n",
       " '000110000110',\n",
       " '000110100100',\n",
       " '000111000100',\n",
       " '000111100000',\n",
       " '001000001101',\n",
       " '001000011100',\n",
       " '001001001001',\n",
       " '001001011000',\n",
       " '001010000101',\n",
       " '001010010100',\n",
       " '001011000001',\n",
       " '001011010000',\n",
       " '001100001100',\n",
       " '001101001000',\n",
       " '001110000100',\n",
       " '001111000000',\n",
       " '010000001011',\n",
       " '010000011010',\n",
       " '010000101001',\n",
       " '010000111000',\n",
       " '010010000011',\n",
       " '010010010010',\n",
       " '010010100001',\n",
       " '010010110000',\n",
       " '010100001010',\n",
       " '010100101000',\n",
       " '010110000010',\n",
       " '010110100000',\n",
       " '011000001001',\n",
       " '011000011000',\n",
       " '011010000001',\n",
       " '011010010000',\n",
       " '011100001000',\n",
       " '011110000000',\n",
       " '100000000111',\n",
       " '100000010110',\n",
       " '100000100101',\n",
       " '100000110100',\n",
       " '100001000011',\n",
       " '100001010010',\n",
       " '100001100001',\n",
       " '100011100000',\n",
       " '100100000110',\n",
       " '100100100100',\n",
       " '100101000010',\n",
       " '100101100000',\n",
       " '101000000101',\n",
       " '101000010100',\n",
       " '101001000001',\n",
       " '101001010000',\n",
       " '101100000100',\n",
       " '101101000000',\n",
       " '110000000011',\n",
       " '110000010010',\n",
       " '110000100001',\n",
       " '110000110000',\n",
       " '110100000010',\n",
       " '110100100000',\n",
       " '111000000001',\n",
       " '111000010000',\n",
       " '111100000000']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_states = load_labels()\n",
    "game_states = sorted(game_states)\n",
    "game_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 128\n",
    "image_width = 128\n",
    "batch_size = 81\n",
    "\n",
    "def load_data():\n",
    "    # Load Train Data\n",
    "    train_images = tf.keras.utils.image_dataset_from_directory(\"./BBTrD/\", batch_size=batch_size, image_size=(image_height, image_width), shuffle=False)\n",
    "\n",
    "    # Load Test Data\n",
    "    test_images =tf.keras.utils.image_dataset_from_directory(\"./BBTeD/\", batch_size=batch_size, image_size=(image_height, image_width), shuffle=False)\n",
    "    return train_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81 files belonging to 81 classes.\n",
      "Found 34 files belonging to 34 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000001111',\n",
       " '000000011110',\n",
       " '000000101101',\n",
       " '000000111100',\n",
       " '000001001011',\n",
       " '000001011010',\n",
       " '000001101001',\n",
       " '000001111000',\n",
       " '000010000111',\n",
       " '000010010110',\n",
       " '000010100101',\n",
       " '000010110100',\n",
       " '000011000011',\n",
       " '000011010010',\n",
       " '000011100001',\n",
       " '000011110000',\n",
       " '000100001110',\n",
       " '000100101100',\n",
       " '000101001010',\n",
       " '000101101000',\n",
       " '000110000110',\n",
       " '000110100100',\n",
       " '000111000100',\n",
       " '000111100000',\n",
       " '001000001101',\n",
       " '001000011100',\n",
       " '001001001001',\n",
       " '001001011000',\n",
       " '001010000101',\n",
       " '001010010100',\n",
       " '001011000001',\n",
       " '001011010000',\n",
       " '001100001100',\n",
       " '001101001000',\n",
       " '001110000100',\n",
       " '001111000000',\n",
       " '010000001011',\n",
       " '010000011010',\n",
       " '010000101001',\n",
       " '010000111000',\n",
       " '010010000011',\n",
       " '010010010010',\n",
       " '010010100001',\n",
       " '010010110000',\n",
       " '010100001010',\n",
       " '010100101000',\n",
       " '010110000010',\n",
       " '010110100000',\n",
       " '011000001001',\n",
       " '011000011000',\n",
       " '011010000001',\n",
       " '011010010000',\n",
       " '011100001000',\n",
       " '011110000000',\n",
       " '100000000111',\n",
       " '100000010110',\n",
       " '100000100101',\n",
       " '100000110100',\n",
       " '100001000011',\n",
       " '100001010010',\n",
       " '100001100001',\n",
       " '100011100000',\n",
       " '100100000110',\n",
       " '100100100100',\n",
       " '100101000010',\n",
       " '100101100000',\n",
       " '101000000101',\n",
       " '101000010100',\n",
       " '101001000001',\n",
       " '101001010000',\n",
       " '101100000100',\n",
       " '101101000000',\n",
       " '110000000011',\n",
       " '110000010010',\n",
       " '110000100001',\n",
       " '110000110000',\n",
       " '110100000010',\n",
       " '110100100000',\n",
       " '111000000001',\n",
       " '111000010000',\n",
       " '111100000000']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize & Rescale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    keras.layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "train_images = train_images.map(lambda x, y: (resize_and_rescale(x), y))\n",
    "test_images = train_images.map(lambda x, y: (resize_and_rescale(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "data_flip = tf.keras.Sequential([\n",
    "  keras.layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "])\n",
    "\n",
    "data_rotation = tf.keras.Sequential([\n",
    "  keras.layers.RandomRotation(0.2)\n",
    "])\n",
    "\n",
    "flipped_images = train_images.map(lambda x, y: (data_flip(x), y))\n",
    "rotated_images = train_images.map(lambda x, y: (data_rotation(x), y))\n",
    "\n",
    "train_images = train_images.concatenate(flipped_images)\n",
    "train_images = train_images.concatenate(rotated_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the VGG model\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 57s 16s/step - loss: 57.3983 - accuracy: 0.0247 - val_loss: 98.3358 - val_accuracy: 0.0294\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 60s 18s/step - loss: 68.2289 - accuracy: 0.1440 - val_loss: 105.7269 - val_accuracy: 0.0294\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 66s 18s/step - loss: 71.1418 - accuracy: 0.2716 - val_loss: 101.8980 - val_accuracy: 0.0588\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 65s 18s/step - loss: 72.2350 - accuracy: 0.3004 - val_loss: 111.2792 - val_accuracy: 0.0294\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 67s 19s/step - loss: 60.9364 - accuracy: 0.4198 - val_loss: 108.5960 - val_accuracy: 0.0294\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 71s 23s/step - loss: 53.4034 - accuracy: 0.4527 - val_loss: 96.2907 - val_accuracy: 0.0882\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 62s 17s/step - loss: 42.3240 - accuracy: 0.5350 - val_loss: 87.3350 - val_accuracy: 0.0294\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 60s 17s/step - loss: 38.3662 - accuracy: 0.5844 - val_loss: 86.5005 - val_accuracy: 0.0294\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 74s 22s/step - loss: 26.5271 - accuracy: 0.6173 - val_loss: 84.2700 - val_accuracy: 0.0588\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 69s 18s/step - loss: 19.3675 - accuracy: 0.6831 - val_loss: 75.2824 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e371e10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 81\n",
    "num_epochs = 10\n",
    "# we will be freezing the base model's layers in order to keep the weights in the optimal condition they were trained in\n",
    "for layer in vgg_conv.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# new classifier model, which consists of the old model's layers plus some new ones\n",
    "extra_layers = vgg_conv.output\n",
    "extra_layers = keras.layers.Flatten()(extra_layers)\n",
    "extra_layers = keras.layers.Dense(1024, activation='relu')(extra_layers)\n",
    "predictions = keras.layers.Dense(num_classes, activation='softmax')(extra_layers)\n",
    "\n",
    "# create the new model\n",
    "new_model = keras.models.Model(inputs=vgg_conv.input, outputs=predictions)\n",
    "\n",
    "# compile the model\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "new_model.fit(train_images, epochs=num_epochs, validation_data=test_images)\n",
    "\n",
    "# print(train_images)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1024)              8389632   \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 81)                83025     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,187,345\n",
      "Trainable params: 8,472,657\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
